{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o3mwp2je15M"
      },
      "source": [
        "# Imports and MRI Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oPzvbq6h7OV"
      },
      "outputs": [],
      "source": [
        "!pip install nilearn\n",
        "!pip install -q kaggle\n",
        "\n",
        "#Imports for preprocessing, scikitlearn model imports still needed\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import nibabel as nib\n",
        "import random\n",
        "from nilearn.masking import compute_epi_mask\n",
        "from nilearn.masking import apply_mask\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import zipfile\n",
        "from google.colab import files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4lHoNSce15N"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "import os, zipfile\n",
        "\n",
        "# 1) Upload kaggle.json\n",
        "print(\"Upload your kaggle.json file\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 2) Find the uploaded filename dynamically\n",
        "kaggle_filename = list(uploaded.keys())[0]\n",
        "print(\"Using uploaded file:\", kaggle_filename)\n",
        "\n",
        "# 3) Put it where Kaggle CLI expects it\n",
        "kaggle_dir = os.path.join(os.path.expanduser(\"~\"), \".kaggle\")\n",
        "os.makedirs(kaggle_dir, exist_ok=True)\n",
        "\n",
        "with open(os.path.join(kaggle_dir, \"kaggle.json\"), \"wb\") as f:\n",
        "    f.write(uploaded[kaggle_filename])\n",
        "\n",
        "# 4) Fix permissions\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "DATA_DIR = \"/content/brats2020\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "zip_path = os.path.join(DATA_DIR, \"brats20-dataset-training-validation.zip\")\n",
        "extracted_dir = os.path.join(DATA_DIR, \"BraTS2020_TrainingData\")\n",
        "\n",
        "# Download only if zip is missing\n",
        "if not os.path.exists(zip_path):\n",
        "    print(\"Downloading dataset from Kaggle...\")\n",
        "    !kaggle datasets download -d awsaf49/brats20-dataset-training-validation -p $DATA_DIR\n",
        "else:\n",
        "    print(\"Zip already exists, skipping download.\")\n",
        "\n",
        "!ls -lh $DATA_DIR\n",
        "\n",
        "# Only unzip if we don't see the extracted folder yet\n",
        "if not os.path.isdir(extracted_dir):\n",
        "    print(\"Extracting zip... this can take a few minutes.\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(DATA_DIR)\n",
        "    print(\"Extraction complete.\")\n",
        "    # Optional: delete zip to save space\n",
        "    os.remove(zip_path)\n",
        "    print(\"Removed zip file.\")\n",
        "else:\n",
        "    print(\"Found extracted directory, skipping unzip.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWHulVRPe15O"
      },
      "outputs": [],
      "source": [
        "!pip install nilearn\n",
        "!pip install -q numpy pandas matplotlib nibabel nilearn scikit-learn scikit-fuzzy scipy\n",
        "!pip install -q seaborn tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFRJN0CPmV_Z"
      },
      "outputs": [],
      "source": [
        "TEST_MODE = True  # Set to False for full dataset\n",
        "MAX_TEST_PATIENTS = 45\n",
        "\n",
        "if TEST_MODE:\n",
        "    print(f\"TEST MODE: Will process only {MAX_TEST_PATIENTS} patients\")\n",
        "else:\n",
        "    print(\"FULL MODE: Processing all patients\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdpflXhQe15O"
      },
      "outputs": [],
      "source": [
        "# Imports for preprocessing, scikitlearn model imports still needed\n",
        "import os, random, warnings, zipfile\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from nilearn.masking import apply_mask\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLTZiNUAe15O"
      },
      "outputs": [],
      "source": [
        "# Load and Organize files\n",
        "DATA_ROOT = \"/content/brats2020\"\n",
        "\n",
        "TRAIN_DIR = os.path.join(\n",
        "    DATA_ROOT, \"BraTS2020_TrainingData\", \"MICCAI_BraTS2020_TrainingData\"\n",
        ")\n",
        "\n",
        "print(\"Train dir:\", TRAIN_DIR)\n",
        "\n",
        "def load_patient(patient_dir):\n",
        "    \"\"\"Load all modalities for a single BraTS patient.\"\"\"\n",
        "    pid = os.path.basename(patient_dir)\n",
        "\n",
        "    def load_mod(mod):\n",
        "        # Kaggle BraTS files are .nii, not .nii.gz\n",
        "        f = os.path.join(patient_dir, f\"{pid}_{mod}.nii\")\n",
        "        return nib.load(f).get_fdata().astype(np.float32)\n",
        "\n",
        "    flair = load_mod(\"flair\")\n",
        "    t1    = load_mod(\"t1\")\n",
        "    t1ce  = load_mod(\"t1ce\")\n",
        "    t2    = load_mod(\"t2\")\n",
        "    seg   = load_mod(\"seg\")\n",
        "\n",
        "    return {\n",
        "        \"PID\": pid,\n",
        "        \"FLAIR\": flair,\n",
        "        \"T1\": t1,\n",
        "        \"T1CE\": t1ce,\n",
        "        \"T2\": t2,\n",
        "        \"SEG\": seg,\n",
        "    }\n",
        "\n",
        "patients = {}\n",
        "masked_patients = {}\n",
        "\n",
        "patient_list = sorted([d for d in os.listdir(TRAIN_DIR) if os.path.isdir(os.path.join(TRAIN_DIR, d))])\n",
        "\n",
        "if TEST_MODE:\n",
        "    patient_list = patient_list[:MAX_TEST_PATIENTS]\n",
        "    print(f\"TEST MODE: Processing only first {MAX_TEST_PATIENTS} patients\\n\")\n",
        "\n",
        "for patient_id in patient_list:\n",
        "    patient_path = os.path.join(TRAIN_DIR, patient_id)\n",
        "\n",
        "    try:\n",
        "        patient_data = load_patient(patient_path)\n",
        "        patients[patient_id] = {\n",
        "            \"T1\": patient_data[\"T1\"],\n",
        "            \"T1CE\": patient_data[\"T1CE\"],\n",
        "            \"T2\": patient_data[\"T2\"],\n",
        "            \"FLAIR\": patient_data[\"FLAIR\"],\n",
        "            \"SEG\": patient_data[\"SEG\"]\n",
        "        }\n",
        "        print(f\"Loaded {patient_id} → {list(patients[patient_id].keys())}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Skipped {patient_id} (error: {e})\")\n",
        "\n",
        "print(f\"\\n Total patients loaded: {len(patients)}\")\n",
        "if len(patients) == 0:\n",
        "    print(f\"WARNING: No patients loaded! Check the directory structure.\")\n",
        "    print(f\"Contents of {TRAIN_DIR}:\")\n",
        "    if os.path.exists(TRAIN_DIR):\n",
        "        print(os.listdir(TRAIN_DIR)[:10])  # Show first 10 items\n",
        "    else:\n",
        "        print(f\"Directory does not exist: {TRAIN_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKxp4EIqe15P"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0mgP6gAe15P"
      },
      "outputs": [],
      "source": [
        "def visualize_random_patient(patients_dict, slice_idx=None):\n",
        "    \"\"\"\n",
        "    Visualize one folder of images with random patient.\n",
        "    \"\"\"\n",
        "    # Pick a random patient\n",
        "    patient_id = random.choice(list(patients_dict.keys()))\n",
        "    data = patients_dict[patient_id]\n",
        "    modalities = ['T1', 'T1CE', 'T2', 'FLAIR', 'SEG']\n",
        "\n",
        "    # Use middle slice if none given\n",
        "    if slice_idx is None:\n",
        "        slice_idx = data['T1'].shape[2] // 2\n",
        "\n",
        "    # Plot all modalities\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(22, 5))\n",
        "    for i, mod in enumerate(modalities):\n",
        "        img = data[mod][:, :, slice_idx]\n",
        "        axes[i].imshow(img.T, cmap='gray' if mod != 'SEG' else 'jet', origin='lower')\n",
        "        axes[i].set_title(mod)\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.suptitle(f\"Patient: {patient_id} | Slice {slice_idx}\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.85)\n",
        "    plt.show()\n",
        "\n",
        "visualize_random_patient(patients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRfSjyjQe15P"
      },
      "outputs": [],
      "source": [
        "# Get the first available patient\n",
        "patient_key = list(patients.keys())[0]\n",
        "slice_idx = 77\n",
        "flair = patients[patient_key]['FLAIR']\n",
        "seg = patients[patient_key]['SEG']\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(flair[:, :, slice_idx], cmap='gray')\n",
        "plt.imshow(seg[:, :, slice_idx], cmap='jet', alpha=0.5)\n",
        "plt.title(f'FLAIR + Segmentation - {patient_key}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVbrTq8ce15P"
      },
      "source": [
        "# Apply Brain Mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnCmW6yse15P"
      },
      "outputs": [],
      "source": [
        "masked_patients = {}\n",
        "\n",
        "for patient_id, data in patients.items():\n",
        "\n",
        "    #Create brain mask by combining modalities\n",
        "    #Any voxel > 0 in ANY modality is considered part of the brain\n",
        "    mask = np.zeros_like(data['T1'], dtype=bool)\n",
        "    for mod in ['T1', 'T1CE', 'T2', 'FLAIR']:\n",
        "        mask |= (data[mod] > 0)\n",
        "\n",
        "    #Store masked data and mask image\n",
        "    masked_patients[patient_id] = {\n",
        "        \"masked_modalities\": {\n",
        "            \"T1\":    data['T1'],\n",
        "            \"T1CE\":  data['T1CE'],\n",
        "            \"T2\":    data['T2'],\n",
        "            \"FLAIR\": data['FLAIR'],\n",
        "        },\n",
        "        \"mask_img\": nib.Nifti1Image(mask.astype(np.uint8), np.eye(4)),\n",
        "        \"SEG\" : data[\"SEG\"]\n",
        "    }\n",
        "\n",
        "    print(f\"{patient_id}: Brain voxels = {mask.sum():,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBFEXZfOe15P"
      },
      "outputs": [],
      "source": [
        "pid = random.choice(list(masked_patients.keys()))\n",
        "mask = masked_patients[pid][\"mask_img\"].get_fdata().astype(bool)\n",
        "flair = masked_patients[pid][\"masked_modalities\"][\"FLAIR\"]\n",
        "\n",
        "z = flair.shape[2] // 2\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow((flair * mask)[:, :, z].T, cmap='gray', origin='lower')\n",
        "plt.title(f\"{pid} | Brain Mask Applied\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPZrtYqse15P"
      },
      "source": [
        "# Intensity Clipping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RV2eOyG_e15Q"
      },
      "outputs": [],
      "source": [
        "def intensity_clipping(volume, mask=None, lower=1, upper=99):\n",
        "    \"\"\"\n",
        "    percentile intensity clipping on an MRI volume.\n",
        "    Taken from nnU-Net (Isensee et al., Nature Methods 2021).\n",
        "    \"\"\"\n",
        "\n",
        "    # If no mask provided, clip across entire non-zero voxels\n",
        "    if mask is None:\n",
        "        mask = volume > 0\n",
        "\n",
        "    # Extract values ONLY inside the brain (avoid background = 0)\n",
        "    brain_voxels = volume[mask]\n",
        "\n",
        "    # Compute percentile bounds\n",
        "    p_low, p_high = np.percentile(brain_voxels, [lower, upper])\n",
        "\n",
        "    # Clip intensities\n",
        "    clipped = np.clip(volume, p_low, p_high)\n",
        "\n",
        "    return clipped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjvlCDYge15Q"
      },
      "source": [
        "# Z Score Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FcBuCSRe15Q"
      },
      "outputs": [],
      "source": [
        "def zscore_normalization(volume, mask=None):\n",
        "    \"\"\"\n",
        "    Z-score normalize inside the brain mask (mean=0, std=1).\n",
        "    Validated by DeepCluster (ECCV 2018), FSL, SPM, FreeSurfer, and nnU-Net.\n",
        "    \"\"\"\n",
        "\n",
        "    if mask is None:\n",
        "        mask = volume > 0  # avoid background\n",
        "\n",
        "    brain_voxels = volume[mask]\n",
        "\n",
        "    mean = brain_voxels.mean()\n",
        "    std  = brain_voxels.std()\n",
        "\n",
        "    if std == 0:\n",
        "        # Extremely rare, but prevents division by zero\n",
        "        return volume - mean\n",
        "\n",
        "    normed = (volume - mean) / std\n",
        "    return normed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaE_Cfpze15Q"
      },
      "source": [
        "# Multi-Channel Feature Vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzJrhK3Ue15Q"
      },
      "outputs": [],
      "source": [
        "voxel_data = {}   # stores X matrix per patient\n",
        "\n",
        "for pid, entry in masked_patients.items():\n",
        "\n",
        "    mask = entry[\"mask_img\"].get_fdata().astype(bool)\n",
        "    mods = entry[\"masked_modalities\"]\n",
        "\n",
        "    # 1. Intensity clipping\n",
        "    for mod in [\"T1\", \"T1CE\", \"T2\", \"FLAIR\"]:\n",
        "        mods[mod] = intensity_clipping(mods[mod], mask=mask)\n",
        "\n",
        "    # 2. Z-score normalization\n",
        "    for mod in [\"T1\", \"T1CE\", \"T2\", \"FLAIR\"]:\n",
        "        mods[mod] = zscore_normalization(mods[mod], mask=mask)\n",
        "\n",
        "    masked_patients[pid][\"masked_modalities\"] = mods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcfOtXZue15Q"
      },
      "source": [
        "# Crop Volumes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxlef0cIe15Q"
      },
      "outputs": [],
      "source": [
        "def center_crop(volume, crop_size=128):\n",
        "    \"\"\"\n",
        "    Center crop a 3D MRI volume to crop_size^3.\n",
        "    \"\"\"\n",
        "    x, y, z = volume.shape\n",
        "    cx, cy, cz = x//2, y//2, z//2\n",
        "    half = crop_size // 2\n",
        "\n",
        "    return volume[\n",
        "        cx - half : cx + half,\n",
        "        cy - half : cy + half,\n",
        "        cz - half : cz + half\n",
        "    ]\n",
        "\n",
        "def get_bbox(mask):\n",
        "    \"\"\"Return bounding box of non-zero region.\"\"\"\n",
        "    coords = np.array(np.where(mask))\n",
        "    zmin, ymin, xmin = coords.min(axis=1)\n",
        "    zmax, ymax, xmax = coords.max(axis=1)\n",
        "    return (zmin, zmax, ymin, ymax, xmin, xmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYmU_yr7e15Q"
      },
      "outputs": [],
      "source": [
        "cropped_patients = {}\n",
        "\n",
        "for pid, entry in masked_patients.items():\n",
        "    mods = entry[\"masked_modalities\"]\n",
        "    seg  = entry[\"SEG\"]\n",
        "    mask = entry[\"mask_img\"].get_fdata().astype(bool)\n",
        "\n",
        "    #Compute bounding box ONCE from brain mask\n",
        "    zmin, zmax, ymin, ymax, xmin, xmax = get_bbox(mask)\n",
        "\n",
        "    #Crop everything using SAME bounding box\n",
        "    cropped_mods = {}\n",
        "    for mod in [\"T1\", \"T1CE\", \"T2\", \"FLAIR\"]:\n",
        "        vol = mods[mod]\n",
        "        cropped_mods[mod] = vol[zmin:zmax+1,\n",
        "                                ymin:ymax+1,\n",
        "                                xmin:xmax+1]\n",
        "\n",
        "    cropped_seg = seg[zmin:zmax+1,\n",
        "                      ymin:ymax+1,\n",
        "                      xmin:xmax+1]\n",
        "\n",
        "    cropped_mask = mask[zmin:zmax+1,\n",
        "                        ymin:ymax+1,\n",
        "                        xmin:xmax+1]\n",
        "\n",
        "    #Save them\n",
        "    cropped_patients[pid] = {\n",
        "        \"masked_modalities\": cropped_mods,\n",
        "        \"mask\": cropped_mask,\n",
        "        \"SEG\": cropped_seg\n",
        "    }\n",
        "\n",
        "    print(f\"{pid} cropped to {cropped_mods['FLAIR'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvgfVpCFe15Q"
      },
      "source": [
        "# ROI Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6TND9vhe15Q"
      },
      "outputs": [],
      "source": [
        "roi_patients = {}\n",
        "\n",
        "for pid, entry in cropped_patients.items():\n",
        "    mods = entry[\"masked_modalities\"]\n",
        "    flair = mods[\"FLAIR\"]\n",
        "    t1ce  = mods[\"T1CE\"]\n",
        "    mask  = entry[\"mask\"]     # brain mask in cropped space\n",
        "\n",
        "    # ----------- SIMPLE ROI -----------\n",
        "    # 1) Basic condition: include all non-zero FLAIR voxels inside the brain mask\n",
        "    roi = (flair > 0) & mask\n",
        "\n",
        "    # 2) Optional soft T1CE enhancement contribution\n",
        "    #    Helps WT slightly, but does not over-prune like the new ROI\n",
        "    t1ce_thr = np.percentile(t1ce[mask], 75)\n",
        "    roi = roi | (t1ce > t1ce_thr)\n",
        "\n",
        "    # No morphological operations\n",
        "    # No connected component pruning\n",
        "    # Purely intensity-based\n",
        "\n",
        "    roi_patients[pid] = {\n",
        "        \"roi\": roi,\n",
        "        \"SEG\": entry[\"SEG\"],\n",
        "        \"masked_modalities\": mods,\n",
        "        \"mask\": mask\n",
        "    }\n",
        "\n",
        "    print(f\"{pid}: ROI voxels = {roi.sum()} / {mask.sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icisxB2ue15R"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJjye7HEe15R"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "# pca = PCA(n_components=3, random_state=42)   # comment out to disable PCA\n",
        "\n",
        "voxel_data = {}\n",
        "\n",
        "for pid, entry in roi_patients.items():\n",
        "    roi = entry[\"roi\"]\n",
        "    mods = entry[\"masked_modalities\"]\n",
        "\n",
        "    X = np.vstack([\n",
        "        mods[\"T1\"][roi],\n",
        "        mods[\"T1CE\"][roi],\n",
        "        mods[\"T2\"][roi],\n",
        "        mods[\"FLAIR\"][roi]\n",
        "    ]).T\n",
        "\n",
        "    # If you want to use pca, do pca.fit instead\n",
        "    X_std = scaler.fit_transform(X)\n",
        "\n",
        "    voxel_data[pid] = {\n",
        "        \"X_std\": X_std,  # If using pca change to X_pca\n",
        "        \"roi\": roi,\n",
        "        \"SEG\": entry[\"SEG\"],\n",
        "        \"masked_modalities\": mods,\n",
        "        \"mask\": entry[\"mask\"]\n",
        "    }\n",
        "\n",
        "    print(f\"{pid}: Using NON-PCA standardized features → {X_std.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17re_dHce15R"
      },
      "source": [
        "# Dimensionality Reduction (Optional PCA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLLKlITqe15R"
      },
      "outputs": [],
      "source": [
        "print(\"\\nFitting PCA globally...\")\n",
        "\n",
        "# Fit PCA on all patients' standardized data\n",
        "all_X_std = np.concatenate([entry[\"X_std\"] for entry in voxel_data.values()])\n",
        "print(\"All X_std shape:\", all_X_std.shape)\n",
        "\n",
        "pca = PCA(n_components=3, random_state=42)\n",
        "pca.fit(all_X_std)\n",
        "\n",
        "# Transform each patient\n",
        "for pid, entry in voxel_data.items():\n",
        "    X_std = entry[\"X_std\"]\n",
        "    entry[\"X_pca\"] = pca.transform(X_std)\n",
        "    print(f\"{pid}: X_pca shape = {entry['X_pca'].shape}\")\n",
        "\n",
        "print(\"PCA transformation complete.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MNJoNXee15R"
      },
      "outputs": [],
      "source": [
        "pid = list(voxel_data.keys())[0]\n",
        "X_pca = voxel_data[pid][\"X_pca\"]\n",
        "\n",
        "print(f\"\\nPCA QC for {pid}\")\n",
        "print(\"PCA component means:\", X_pca.mean(axis=0))\n",
        "print(\"PCA component stds :\", X_pca.std(axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyGMr-q7e15R"
      },
      "source": [
        "# Spectral Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FuNeFLWe15R"
      },
      "outputs": [],
      "source": [
        "# Spectral clustering with subsampling + label propagation\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import time\n",
        "\n",
        "# --- Hyperparameters ---\n",
        "k = 4                     # number of clusters\n",
        "SUBSAMPLE_SIZE = 20000    # max voxels per patient for spectral step\n",
        "N_NEIGHBORS_GRAPH = 30    # neighbors for k-NN affinity graph (spectral)\n",
        "N_NEIGHBORS_PROP = 5      # neighbors for k-NN label propagation\n",
        "\n",
        "rng = np.random.default_rng(546)\n",
        "\n",
        "for pid, entry in voxel_data.items():\n",
        "    X_pca = entry[\"X_pca\"]    # shape (N_voxels, 3)\n",
        "    roi   = entry[\"roi\"]      # boolean / index mask into 3D mask\n",
        "    mask  = entry[\"mask\"]     # 3D brain mask\n",
        "\n",
        "    N = X_pca.shape[0]\n",
        "    print(f\"\\n=== {pid} ===\")\n",
        "    print(f\"Total voxels in ROI: {N}\")\n",
        "\n",
        "    if N < k:\n",
        "        print(f\"  [SKIP] N={N} < k={k}, not enough voxels to cluster.\")\n",
        "        continue\n",
        "\n",
        "    # --- 1) Subsample voxels for spectral clustering ---\n",
        "    if N > SUBSAMPLE_SIZE:\n",
        "        idx_sub = rng.choice(N, size=SUBSAMPLE_SIZE, replace=False)\n",
        "    else:\n",
        "        idx_sub = np.arange(N)\n",
        "\n",
        "    X_sub = X_pca[idx_sub]\n",
        "    print(f\"  Using subset of {X_sub.shape[0]} voxels for spectral clustering.\")\n",
        "\n",
        "    # --- 2) Spectral clustering on the subset (k-NN graph) ---\n",
        "    spectral = SpectralClustering(\n",
        "        n_clusters=k,\n",
        "        eigen_solver=\"arpack\",\n",
        "        affinity=\"nearest_neighbors\",\n",
        "        n_neighbors=N_NEIGHBORS_GRAPH,\n",
        "        assign_labels=\"kmeans\",\n",
        "        n_init=5,\n",
        "        random_state=0,\n",
        "    )\n",
        "\n",
        "    t0 = time.time()\n",
        "    try:\n",
        "        labels_sub = spectral.fit_predict(X_sub).astype(np.int32)\n",
        "    except MemoryError:\n",
        "        print(\"  [ERROR] MemoryError in spectral clustering on subset. \"\n",
        "              \"Try reducing SUBSAMPLE_SIZE or N_NEIGHBORS_GRAPH.\")\n",
        "        continue\n",
        "    t1 = time.time()\n",
        "    print(f\"  Spectral (subset) done in {t1 - t0:.1f} s\")\n",
        "\n",
        "    # --- 3) Label propagation with k-NN classifier ---\n",
        "    clf = KNeighborsClassifier(n_neighbors=N_NEIGHBORS_PROP)\n",
        "    clf.fit(X_sub, labels_sub)\n",
        "\n",
        "    t0 = time.time()\n",
        "    labels_full = clf.predict(X_pca).astype(np.int32)\n",
        "    t1 = time.time()\n",
        "    print(f\"  k-NN label propagation done in {t1 - t0:.1f} s\")\n",
        "\n",
        "    # Store 1D labels (all ROI voxels)\n",
        "    entry[\"spectral_labels\"] = labels_full\n",
        "\n",
        "    # --- 4) Map labels back to 3D volume ---\n",
        "    labels_3d = np.zeros_like(mask, dtype=np.int32)\n",
        "    labels_3d[roi] = labels_full\n",
        "    entry[\"spectral_labels_3d\"] = labels_3d\n",
        "\n",
        "    print(\"  Stored 'spectral_labels' and 'spectral_labels_3d'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vK0ZUpGe15R"
      },
      "outputs": [],
      "source": [
        "# Pick a patient to visualize\n",
        "pid = list(voxel_data.keys())[1]  # or any specific ID\n",
        "entry = voxel_data[pid]\n",
        "flair_vol = entry[\"masked_modalities\"][\"FLAIR\"]\n",
        "labels_vol = entry[\"spectral_labels_3d\"]\n",
        "\n",
        "slice_idx = flair_vol.shape[2] // 2\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(flair_vol[:, :, slice_idx].T, cmap=\"gray\", origin=\"lower\")\n",
        "plt.imshow(labels_vol[:, :, slice_idx].T,\n",
        "           cmap=\"viridis\",\n",
        "           alpha=0.4,\n",
        "           origin=\"lower\")\n",
        "plt.title(f\"{pid} | Spectral clusters (k={k}) on FLAIR\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBI7G4Y1e15R"
      },
      "source": [
        "# Evaluation: Cluster Alignment and Dice Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzMHxIgLe15R"
      },
      "outputs": [],
      "source": [
        "# --- Dice helper ---\n",
        "def dice(pred, true):\n",
        "    pred = pred.astype(bool)\n",
        "    true = true.astype(bool)\n",
        "\n",
        "    if pred.sum() + true.sum() == 0:\n",
        "        return 1.0\n",
        "    if pred.sum() == 0 or true.sum() == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return 2 * np.sum(pred & true) / (pred.sum() + true.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCkmbUjSe15R"
      },
      "outputs": [],
      "source": [
        "# 1) Align Spectral clusters → GT labels (per patient)\n",
        "spectral_aligned_labels = {}\n",
        "\n",
        "for pid, entry in voxel_data.items():\n",
        "    print(f\"\\nAligning Spectral clusters for {pid}\")\n",
        "\n",
        "    roi = entry[\"roi\"]\n",
        "    spectral_labels = entry[\"spectral_labels\"]        # shape (N_voxels,)\n",
        "\n",
        "    # Get SEG in ROI space\n",
        "    seg_vol = entry[\"SEG\"]\n",
        "    seg_flat = seg_vol[roi].astype(int)  # shape (N_voxels,)\n",
        "\n",
        "    if len(seg_flat) != len(spectral_labels):\n",
        "        print(f\"Length mismatch for {pid}: seg={len(seg_flat)}, spectral={len(spectral_labels)}\")\n",
        "        continue\n",
        "\n",
        "    # Map BraTS labels {1,2,4} → {0,1,2}, everything else → -1 (ignore)\n",
        "    seg_map = {1: 0, 2: 1, 4: 2}\n",
        "    true_seg = np.array([seg_map.get(int(v), -1) for v in seg_flat])\n",
        "\n",
        "    # Only use voxels with valid GT labels for alignment\n",
        "    valid_idx = true_seg >= 0\n",
        "    true_valid = true_seg[valid_idx]\n",
        "    pred_valid = spectral_labels[valid_idx]\n",
        "\n",
        "    # Confusion matrix rows = GT, cols = clusters\n",
        "    cm = confusion_matrix(true_valid, pred_valid, labels=[0, 1, 2])\n",
        "\n",
        "    # Hungarian matching to find best cluster → GT mapping\n",
        "    row_ind, col_ind = linear_sum_assignment(-cm)  # maximize agreement\n",
        "    mapping = dict(zip(col_ind, row_ind))\n",
        "    print(f\"{pid}: cluster→GT mapping: {mapping}\")\n",
        "\n",
        "    # Apply mapping to ALL voxels\n",
        "    aligned = np.array([mapping.get(int(c), -1) for c in spectral_labels])\n",
        "    spectral_aligned_labels[pid] = aligned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKQN2Nnce15S"
      },
      "outputs": [],
      "source": [
        "# 2) Compute Dice scores (WT, TC, ET) for each patient\n",
        "dice_scores_spectral = {}\n",
        "\n",
        "for pid, entry in voxel_data.items():\n",
        "    if pid not in spectral_aligned_labels:\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nComputing Dice for Spectral – {pid}\")\n",
        "\n",
        "    roi = entry[\"roi\"]\n",
        "    seg_vol = entry[\"SEG\"]\n",
        "    seg_flat = seg_vol[roi].astype(int)\n",
        "\n",
        "    seg_map = {1: 0, 2: 1, 4: 2}\n",
        "    true_seg = np.array([seg_map.get(int(v), -1) for v in seg_flat])\n",
        "\n",
        "    pred_seg = spectral_aligned_labels[pid]\n",
        "\n",
        "    if len(pred_seg) != len(true_seg):\n",
        "        print(f\"Shape mismatch: pred={len(pred_seg)}, true={len(true_seg)}\")\n",
        "        continue\n",
        "\n",
        "    # --- Region definitions ---\n",
        "\n",
        "    # Whole tumor: any non-background tumor label\n",
        "    true_WT = true_seg > 0\n",
        "    pred_WT = pred_seg > 0\n",
        "\n",
        "    # Tumor core\n",
        "    true_TC = np.isin(true_seg, [0, 2])\n",
        "    pred_TC = np.isin(pred_seg, [0, 2])\n",
        "\n",
        "    # Enhancing tumor: label 2\n",
        "    true_ET = (true_seg == 2)\n",
        "    pred_ET = (pred_seg == 2)\n",
        "\n",
        "    WT = dice(pred_WT, true_WT)\n",
        "    TC = dice(pred_TC, true_TC)\n",
        "    ET = dice(pred_ET, true_ET)\n",
        "\n",
        "    dice_scores_spectral[pid] = (WT, TC, ET)\n",
        "    print(f\"{pid}: WT={WT:.4f}, TC={TC:.4f}, ET={ET:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpRN5qsZe15S"
      },
      "source": [
        "# Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60mK0w4Ke15S"
      },
      "outputs": [],
      "source": [
        "def summarize_single_method(dice_scores, method_name=\"Method\"):\n",
        "\n",
        "    # Collect into arrays\n",
        "    WT = np.array([v[0] for v in dice_scores.values()])\n",
        "    TC = np.array([v[1] for v in dice_scores.values()])\n",
        "    ET = np.array([v[2] for v in dice_scores.values()])\n",
        "\n",
        "    summary = {\n",
        "        \"Method\": method_name,\n",
        "        \"WT_mean\": WT.mean(),   \"WT_median\": np.median(WT), \"WT_std\": WT.std(),\n",
        "        \"WT_min\": WT.min(),     \"WT_max\": WT.max(),\n",
        "        \"TC_mean\": TC.mean(),   \"TC_median\": np.median(TC), \"TC_std\": TC.std(),\n",
        "        \"TC_min\": TC.min(),     \"TC_max\": TC.max(),\n",
        "        \"ET_mean\": ET.mean(),   \"ET_median\": np.median(ET), \"ET_std\": ET.std(),\n",
        "        \"ET_min\": ET.min(),     \"ET_max\": ET.max(),\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame([summary])\n",
        "    display(df)\n",
        "    print(\"\\nLaTeX table:\\n\")\n",
        "    print(df.to_latex(index=False, float_format=\"%.4f\"))\n",
        "    return df\n",
        "\n",
        "\n",
        "_ = summarize_single_method(dice_scores_spectral, \"Spectral\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zg4t6Umaoeh"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def visualize_fcm_result(pid, slice_axis='z'):\n",
        "    \"\"\"\n",
        "    Visualize ground-truth vs Spectral clustering segmentation for a given patient.\n",
        "    slice_axis: 'z', 'y', or 'x'\n",
        "    \"\"\"\n",
        "\n",
        "    mods  = cropped_patients[pid][\"masked_modalities\"]\n",
        "    flair = mods[\"FLAIR\"]\n",
        "    seg   = cropped_patients[pid][\"SEG\"]\n",
        "    roi   = voxel_data[pid][\"roi\"]\n",
        "\n",
        "    pred  = spectral_aligned_labels[pid]\n",
        "\n",
        "    # Convert ROI + predictions back into arrays\n",
        "    pred_full = np.zeros_like(seg) - 1\n",
        "    pred_full[roi] = pred\n",
        "\n",
        "    # Choose slice\n",
        "    if slice_axis == 'z':\n",
        "        slice_idx = flair.shape[2] // 2\n",
        "        flair_slice = flair[:,:,slice_idx]\n",
        "        seg_slice   = seg[:,:,slice_idx]\n",
        "        pred_slice  = pred_full[:,:,slice_idx]\n",
        "    elif slice_axis == 'y':\n",
        "        slice_idx = flair.shape[1] // 2\n",
        "        flair_slice = flair[:,slice_idx,:]\n",
        "        seg_slice   = seg[:,slice_idx,:]\n",
        "        pred_slice  = pred_full[:,slice_idx,:]\n",
        "    else:\n",
        "        slice_idx = flair.shape[0] // 2\n",
        "        flair_slice = flair[slice_idx,:,:]\n",
        "        seg_slice   = seg[slice_idx,:,:]\n",
        "        pred_slice  = pred_full[slice_idx,:,:]\n",
        "\n",
        "    # Images\n",
        "    plt.figure(figsize=(14,4))\n",
        "\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.title(f\"{pid} \\u2014 FLAIR\")\n",
        "    plt.imshow(flair_slice.T, cmap='gray', origin='lower')\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.title(\"Ground Truth (SEG)\")\n",
        "    plt.imshow(flair_slice.T, cmap='gray', alpha=0.6, origin='lower')\n",
        "    plt.imshow(seg_slice.T, cmap='jet', alpha=0.4, origin='lower')\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    # Updated title to reflect Spectral Clustering\n",
        "    plt.title(\"Spectral Clustering Prediction (aligned)\")\n",
        "    plt.imshow(flair_slice.T, cmap='gray', alpha=0.6, origin='lower')\n",
        "    plt.imshow(pred_slice.T, cmap='jet', alpha=0.4, origin='lower')\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "#Set specific patient ID for visualization\n",
        "specific_pid = 'BraTS20_Training_001'\n",
        "print(\"Visualizing:\", specific_pid)\n",
        "visualize_fcm_result(specific_pid)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}